# ğŸ§  AI Code Explainer (Monaco Editor Integration)

This project integrates AI directly into a code editor (Monaco Editor).  
When you **select a word or snippet** and click on the **ğŸ¤– Ask AI** button, it calls an AI model (currently OpenAI via Azure Inference) and displays the explanation **inline inside the editor**.  

Future scope:  
- Support **Ollama** models (local inference, no API costs).  
- Build a **VS Code extension** for seamless developer workflows.  

---

## ğŸš€ Features
- Select text in the code editor â†’ click **Ask AI** â†’ get inline AI explanation.
- AI response displayed in a **tooltip** (short version) or **modal** (full explanation).
- Smooth UI with Monaco Editor, tooltips, modals, and loading animations.
- Redux state management for async requests (loading, success, failure).
- Currently supports **Azure OpenAI Inference API**.
- Scalable to other providers (Gemini, Ollama, etc.).

---

## ğŸ›  Tech Stack
**Frontend**  
- âš›ï¸ React.js  
- ğŸ“ Monaco Editor (browser-based code editor)  
- ğŸ¨ CSS-in-JS (inline styles + custom animations)  
- ğŸ—‚ Redux Toolkit (state management)  

**Backend**  
- ğŸŸ¦ Node.js + Express.js  
- ğŸ”— Azure Inference API (OpenAI GPT-4.1)  
- ğŸ” dotenv for environment variables  

**Planned / Future**  
- ğŸ™ Ollama for local model inference  
- ğŸ§© VS Code Extension API for native integration  
- ğŸŒ Multi-provider support (OpenAI, Gemini, Anthropic, etc.)  

---

## ğŸ“‚ Project Structure
- `/frontend` â†’ React app with Monaco Editor & Redux integration  
- `/frontend/components/MonacoEditor.js` â†’ Main editor + AI tooltip & modal  
- `/frontend/components/TooltipOverlay.js` â†’ Floating "Ask AI" button  
- `/frontend/features/textSlice.js` â†’ Redux slice for AI state management  
- `/backend/services/openaiService.js` â†’ Calls Azure Inference API (OpenAI models)  
- `/backend/routes/receiveText.js` â†’ Backend endpoint for handling AI requests  

---

## ğŸ“– How It Works
1. User selects code/text inside Monaco Editor.  
2. Tooltip **ğŸ¤– Ask AI** button appears â†’ click it.  
3. Selected text sent to **backend**.  
4. Backend calls **Azure Inference API (OpenAI GPT-4.1)**.  
5. AI explanation returned â†’ displayed inline in **tooltip** (short version).  
6. User can expand to **modal** for full explanation.  

---

## âš ï¸ Notes
- Requires **Azure AI Inference Token** (or OpenAI API key if switched).  
- Currently uses `openai/gpt-4.1` via `@azure-rest/ai-inference`.  
- **Free-tier OpenAI APIs may be limited** â†’ consider Ollama for local inference.  
- Works only inside **browser Monaco Editor** for now; VS Code extension planned.  

---

## ğŸ› ï¸ Setup
### 1ï¸âƒ£ Backend
```bash
cd backend
npm install



